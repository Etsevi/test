{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92544f14",
   "metadata": {},
   "source": [
    "# IA Générative\n",
    "\n",
    "### Dafnis Krasniqi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298d303f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Introduction à l'IA Générative\n",
    "\n",
    "Ce cours, intitulé **Introduction à l'IA Générative et aux Modèles de Langage de Grande Taille (LLM)**, explique comment l'IA générative permet de créer du contenu (texte, images, etc.) à partir d'un simple prompt textuel, sans avoir besoin de compétences techniques particulières. L'IA générative démocratise ainsi l'accès à des outils puissants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4d6aa8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Objectifs d'apprentissage :**\n",
    "1. Comprendre ce qu'est l'IA générative et comment fonctionnent les LLMs.\n",
    "2. Explorer des cas d'usage dans l'éducation, en particulier grâce aux LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da66657a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### **Évolution de l'IA :**\n",
    "- **Débuts de l'IA :** Les premiers chatbots des années 60 se basaient sur des bases de connaissances limitées.\n",
    "- **Apprentissage automatique (Machine Learning) :** Dans les années 90, des algorithmes statistiques ont été utilisés pour analyser le texte et permettre aux machines de mieux comprendre le langage humain.\n",
    "- **Réseaux de neurones :** Des avancées en matériel ont permis le développement de réseaux de neurones, comme les réseaux neuronaux récurrents (RNN), capables de traiter des séquences plus longues de texte.\n",
    "- **Présent : IA générative et Transformers** : Aujourd'hui, les Transformers ont surmonté les limites des RNNs en traitant de longues séquences de texte et en générant du contenu de manière créative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e6db2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](Images/AI-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeabab72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Fonctionnement des LLMs :**\n",
    "Les LLMs utilisent des **tokenizers** pour convertir le texte en nombres, sur lesquels ils basent leurs prédictions. \n",
    "\n",
    "![title](Images/tokenizer-example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66754996",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "* Les grands modèles de langage (LLM), comme GPT, reçoivent un texte en entrée et génèrent un texte en sortie. Pour ce faire, le texte est d'abord transformé en nombres via un tokenizer, qui divise le texte en segments appelés tokens et les associe à des indices numériques. Ensuite, le modèle prédit un token à chaque étape, en se basant sur une séquence d'entrée. Ce processus fonctionne en une série d'itérations, où le modèle continue d'ajouter des tokens pour former une réponse complète.\n",
    "\n",
    "\n",
    "* La sélection du token de sortie se fait en fonction d'une distribution de probabilité. Cependant, le modèle n'utilise pas toujours le token avec la plus haute probabilité pour garantir de la variation dans les réponses. Ce niveau de variation est contrôlé par un paramètre appelé temperature, permettant d’ajouter une dose de créativité."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d453ae4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Cas d'usage des LLMs :**\n",
    "1. **Résumé de texte**\n",
    "2. **Création d'idées**\n",
    "3. **Complétion de texte**\n",
    "4. **Génération de code**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb8aaeb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](Images/conversation-example.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfcf9ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Limitations de l'IA générative :**\n",
    "L'IA générative n'est pas toujours fiable, elle peut générer des contenus erronés ou biaisés. De plus, elle n'a pas de réelle intelligence émotionnelle ou critique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c173ddb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](Images/students-by-DALLE2.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb66ec6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2 \"Exploring and Comparing Different LLMs\"\n",
    "\n",
    "### Introduction\n",
    "Cette leçon aborde les différents types de Modèles de Langage de Grande Taille (LLMs), comment les tester et les comparer, et comment les déployer. L’objectif est de comprendre les avantages et inconvénients de ces modèles pour choisir le plus adapté aux cas d’usage spécifiques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08b98a2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Objectifs\n",
    "- Choisir le bon modèle pour un usage donné.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec29847a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Les différents types de LLMs\n",
    "Les LLMs peuvent être catégorisés selon leur architecture, leurs données d'entraînement, et leurs cas d’usage. Voici quelques exemples :\n",
    "\n",
    "- **Reconnaissance vocale** : modèles comme Whisper pour la reconnaissance multilingue.\n",
    "- **Génération d’images** : modèles comme DALL-E ou Midjourney.\n",
    "- **Génération de texte** : modèles comme GPT-3.5 ou GPT-4 pour les tâches textuelles.\n",
    "- **Multimodalité** : GPT-4 Turbo permet de traiter du texte et des images simultanément.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490037e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Modèles Open Source vs Propriétaires\n",
    "- **Open Source** : accès libre aux modèles comme Alpaca ou LLaMA, mais avec des limitations en termes de maintenance et d’optimisation.\n",
    "- **Propriétaires** : modèles comme ceux d’OpenAI ou Google Bard, optimisés pour la production mais souvent payants et non modifiables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba6bbe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](Images/Capture.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c639fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Catégories par sortie\n",
    "- **Embeddings** : pour représenter des textes sous forme numérique.\n",
    "- **Génération d'images** : modèles comme DALL-E.\n",
    "- **Génération de texte/code** : pour la génération automatique de contenu textuel ou de code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f88c67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](Images/Embedding.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8eea87",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](Images/Image.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3474c62",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](Images/Text.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59806187",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Architectures\n",
    "- **Modèles Décodeurs seulement** : comme GPT, spécialisés dans la génération de texte.\n",
    "- **Modèles Encodeurs seulement** : comme BERT, spécialisés dans la compréhension du texte.\n",
    "- **Modèles Encodeurs-Décodeurs** : comme T5, capables de générer et de comprendre du texte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b7c722",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attention Is All You Need\n",
    "\n",
    "En 2017, Vaswani et al. ont publié un article intitulé *Attention Is All You Need* lors de la conférence NeurIPS, où ils ont introduit l'architecture *Transformer* originale pour la traduction automatique. Cette architecture a surpassé les modèles *RNN* encodeur-décodeur dominants à l’époque, en étant à la fois plus performante et plus rapide.\n",
    "\n",
    "L'architecture *Transformer* est devenue la base de modèles récents comme *BERT* et *GPT-3*, et a déjà été appliquée dans des domaines comme la vision par ordinateur et l'apprentissage par renforcement. Comprendre cette architecture est donc essentiel pour anticiper les futures tendances de l'apprentissage automatique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae54e8a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Caractéristiques du *Transformer* :\n",
    "L'architecture est présentée comme simple, car elle ne repose ni sur des récurrences ni sur des convolutions, deux concepts courants mais complexes des RNNs et CNNs. Au lieu de cela, elle utilise des mécanismes comme l’encodeur-décodeur, les *word embeddings* et l’attention (*attention mechanism*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85d5d21",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Le mécanisme de self-attention est un concept clé utilisé dans les modèles de language de type Transformer, comme les LLMs. \n",
    "\n",
    "#### Définition\n",
    "Le **self-attention** est une technique qui permet à un modèle de pondérer l'importance de chaque mot (ou token) par rapport aux autres mots d'une phrase lorsqu'il les traite. Autrement dit, chaque mot \"fait attention\" à d'autres mots pour comprendre le contexte dans lequel il est utilisé.\n",
    "\n",
    "![title](Images/attention_m.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c77e1c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Comment cela fonctionne\n",
    "1. **Entrée :** Chaque mot d'une phrase est représenté par un vecteur (une série de nombres).\n",
    "2. **Calcul des Scores d'Attention :** Le mécanisme de self-attention compare chaque mot avec tous les autres mots de la phrase. Il calcule des \"scores d'attention\" pour chaque paire de mots, indiquant à quel point un mot est important par rapport aux autres.\n",
    "3. **Application des Scores :** Ces scores sont utilisés pour ajuster les représentations de chaque mot en fonction de son importance par rapport aux autres mots. Par exemple, dans la phrase \"Le chat mange une souris\", le modèle peut déterminer que \"chat\" est plus lié à \"mange\" qu'à \"souris\".\n",
    "4. **Sortie :** Chaque mot est finalement représenté par une version pondérée qui tient compte de son contexte global dans la phrase.\n",
    "\n",
    "### Pourquoi c'est important\n",
    "Le self-attention permet aux modèles d'IA de traiter efficacement des relations complexes entre les mots, même sur de longues phrases. Cela améliore la compréhension contextuelle, rendant les modèles plus précis pour des tâches comme la traduction, la génération de texte et la réponse aux questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a98c2b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### L'architecture de base : Encodeur-Décodeur\n",
    "Le *Transformer* suit un schéma encodeur-décodeur classique. L’encodeur extrait des caractéristiques à partir d’une phrase d’entrée (par exemple, en anglais), et le décodeur utilise ces caractéristiques pour produire une phrase de sortie (par exemple, une traduction en français).\n",
    "\n",
    "- **Encodeur** : Composé de plusieurs blocs d'encodeurs empilés, qui traitent la phrase d’entrée. Le dernier bloc encodeur génère des caractéristiques qui alimentent le décodeur.\n",
    "- **Décodeur** : Lui aussi constitué de plusieurs blocs, il prend en entrée les caractéristiques produites par l'encodeur et génère la phrase de sortie.\n",
    "\n",
    "Chaque bloc de décodeur reçoit les informations provenant de l'encodeur, créant une interaction continue entre les deux.\n",
    "\n",
    "L'utilisation multiple de blocs (indiquée par *Nx* dans le schéma original) renforce l'efficacité du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77c4f18",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](Images/transformers.png) \n",
    "\n",
    "pour allé plus loin: https://kikaben.com/transformers-encoder-decoder/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddd5642",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](Images/transformers_1.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e8b3a8",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Amélioration des résultats des LLMs\n",
    "Il existe plusieurs approches pour améliorer les performances des LLMs :\n",
    "- **Prompt engineering** : affiner les requêtes pour obtenir de meilleures réponses.\n",
    "- **RAG (Retrieval-Augmented Generation)** : intégrer des données externes à la requête.\n",
    "- **Fine-tuning** : adapter un modèle existant avec des données spécifiques pour un meilleur ajustement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e5d394",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Amélioration des résultats des LLMs\n",
    "L'amélioration des performances des *Large Language Models* (LLMs) est un enjeu clé pour obtenir des résultats plus précis, pertinents et adaptés à des contextes spécifiques. Plusieurs stratégies peuvent être mises en œuvre pour optimiser ces modèles :\n",
    "\n",
    "- **Prompt Engineering** : Le *prompt engineering* consiste à formuler et structurer soigneusement les requêtes adressées aux LLMs pour obtenir des réponses optimales. En ajustant la formulation, en précisant des instructions ou en donnant des exemples, il est possible d'améliorer la compréhension du modèle et la qualité des réponses générées. \n",
    "\n",
    "- **RAG (Retrieval-Augmented Generation)** : Cette méthode combine la génération de texte par LLM avec des données externes récupérées en temps réel via un système de recherche. Cela permet au modèle d’accéder à des informations spécifiques, à jour ou qui ne sont pas incluses dans son corpus d’entraînement. \n",
    "\n",
    "- **Fine-tuning** : Le *fine-tuning* consiste à adapter un modèle de base préentraîné sur des données généralistes à des domaines ou des cas d’usage spécifiques. En réentraînant le modèle avec des jeux de données ciblés, on peut affiner ses capacités pour qu’il devienne plus performant dans un contexte particulier (par exemple, la santé, le droit, la finance, etc.). \n",
    "\n",
    "- **Utilisation de modèles spécialisés ou hybrides** : Combiner plusieurs LLMs ou créer des modèles spécialisés pour des tâches spécifiques peut aussi améliorer les résultats. Par exemple, certains modèles peuvent être conçus pour une meilleure compréhension du langage, tandis que d'autres excellent dans des tâches de génération créative.\n",
    "\n",
    "En combinant ces différentes approches, il est possible de maximiser les performances des LLMs pour des besoins variés et de s’adapter aux exigences spécifiques des utilisateurs et des domaines d'application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590b291d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  3. Introduction à RAG (Retrieval Augmented Generation) et Bases de Données Vectorielles\n",
    "\n",
    "---\n",
    "\n",
    "### Qu'est-ce que le RAG ?\n",
    "- Retrieval Augmented Generation (RAG) est une méthode qui combine les *Large Language Models* (LLMs) avec des données externes.\n",
    "- Elle enrichit les réponses des LLMs en récupérant des informations provenant de bases de connaissances spécifiques.\n",
    "- Utile lorsque les LLMs n'ont pas accès à des informations récentes ou spécialisées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54400e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](Images/how-rag-works.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9905e26",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Pourquoi utiliser RAG ?**\n",
    "- **Améliore la précision** : Les réponses sont basées sur des données actuelles et spécifiques.\n",
    "- **Réduit les erreurs (hallucinations)** : Limite les réponses inventées en utilisant des informations vérifiables.\n",
    "- **Économique** : Moins coûteux que d’entraîner à nouveau un modèle complet (fine-tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9148a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Comment fonctionne le RAG ?**\n",
    "1. **Base de connaissances** : Les documents sont transformés en *embeddings* (représentations numériques).\n",
    "2. **Requête utilisateur** : L'utilisateur pose une question.\n",
    "3. **Récupération des données** : Les *embeddings* similaires sont extraits de la base de données.\n",
    "4. **Génération augmentée** : Le LLM utilise ces données pour enrichir sa réponse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07115d5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Les Bases de Données Vectorielles**\n",
    "- **Qu'est-ce que c'est ?** : Une base de données conçue pour stocker des *embeddings* (représentations vectorielles de texte, images, etc.).\n",
    "- **Pourquoi c'est important ?** : Permet une recherche rapide et efficace de contenu pertinent en fonction des requêtes utilisateurs.\n",
    "- **Exemples** : Azure Cosmos DB, Pinecone, Qdrant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e997d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Processus RAG : Exemple**\n",
    "1. **Ingestion des documents** : Les textes sont découpés et transformés en *embeddings*.\n",
    "2. **Stockage dans une base de données vectorielle**.\n",
    "3. **Requête utilisateur** : Transformée en vecteur pour la recherche.\n",
    "4. **Récupération et génération** : Les données pertinentes sont récupérées et intégrées à la réponse du modèle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d23eec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Avantages du RAG**\n",
    "- **Réponses plus pertinentes** : Meilleures performances sur des tâches spécifiques grâce à des informations récentes.\n",
    "- **Recherche efficace** : Les *embeddings* permettent de trouver des documents proches en signification.\n",
    "- **Personnalisation** : Facilement adaptable à des domaines spécifiques (ex. : support client, apprentissage).\n",
    "\n",
    "\n",
    "### **Applications Pratiques**\n",
    "- **Chatbots** : Améliorer les réponses en intégrant des informations d'entreprise ou des notes personnelles.\n",
    "- **Systèmes de recommandation** : Proposer des contenus (films, articles) basés sur des données stockées.\n",
    "- **Recherche d’images** : Trouver des images similaires via des représentations vectorielles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02691f59",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Conclusion**\n",
    "- **RAG** est une technologie clé pour rendre les LLMs plus performants et pertinents, en les reliant à des bases de données externes.\n",
    "- **Bases de données vectorielles** facilitent cette intégration en permettant une recherche rapide et efficace d’informations adaptées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37865d2c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. les modèles open source\n",
    "\n",
    "### **Introduction aux Modèles Open Source**\n",
    "\n",
    "- Le monde des LLMs open source est en constante évolution.\n",
    "- Cette leçon se concentre sur les modèles open source et leurs avantages.\n",
    "- Comparaison avec les modèles propriétaires dans une autre leçon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ebf1f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Qu'est-ce qu'un Modèle Open Source ?**\n",
    "\n",
    "- Le logiciel open source : partage libre du code sous licence OSI.\n",
    "- Pour les LLMs, les critères d'un modèle open source incluent : Données d'entraînement, poids du modèle, code d'évaluation et de fine-tuning, et métriques.\n",
    "- Peu de modèles répondent à ces critères (ex. : OLMo d'AllenAI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d2c699",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ** Avantages des Modèles Open Source**\n",
    "\n",
    "- **Personnalisables** : Adaptables pour des tâches spécifiques (ex. : génération de code, biologie).\n",
    "- **Coût réduit** : Moins cher que les modèles propriétaires.\n",
    "- **Flexibilité** : Possibilité de combiner différents modèles (ex. : HuggingChat).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3791cf8b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](Images/model-price.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64ba59f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![title](Images/model-price.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe950b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
